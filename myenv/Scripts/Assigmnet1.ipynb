{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f32b25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Very interested  Somewhat interested  \\\n",
      "Big Data (Spark / Hadoop)              1332                  729   \n",
      "Data Analysis / Statistics             1688                  444   \n",
      "Data Journalism                         429                 1081   \n",
      "Data Visualization                     1340                  734   \n",
      "Deep Learning                          1263                  770   \n",
      "\n",
      "                            Not interested  \n",
      "Big Data (Spark / Hadoop)              127  \n",
      "Data Analysis / Statistics              60  \n",
      "Data Journalism                        610  \n",
      "Data Visualization                     102  \n",
      "Deep Learning                          136  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "url = \"https://cocl.us/datascience_survey_data\"\n",
    "df = pd.read_csv(url, index_col=0) #load the first column as the index of the dataframe.\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ded677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Identifier             Edition Statement      Place of Publication  \\\n",
      "0         206                           NaN                    London   \n",
      "1         216                           NaN  London; Virtue & Yorston   \n",
      "2         218                           NaN                    London   \n",
      "3         472                           NaN                    London   \n",
      "4         480  A new edition, revised, etc.                    London   \n",
      "\n",
      "  Date of Publication              Publisher  \\\n",
      "0         1879 [1878]       S. Tinsley & Co.   \n",
      "1                1868           Virtue & Co.   \n",
      "2                1869  Bradbury, Evans & Co.   \n",
      "3                1851          James Darling   \n",
      "4                1857   Wertheim & Macintosh   \n",
      "\n",
      "                                               Title     Author  \\\n",
      "0                  Walter Forbes. [A novel.] By A. A      A. A.   \n",
      "1  All for Greed. [A novel. The dedication signed...  A., A. A.   \n",
      "2  Love the Avenger. By the author of “All for Gr...  A., A. A.   \n",
      "3  Welsh Sketches, chiefly ecclesiastical, to the...  A., E. S.   \n",
      "4  [The World in which I live, and my place in it...  A., E. S.   \n",
      "\n",
      "                                   Contributors  Corporate Author  \\\n",
      "0                               FORBES, Walter.               NaN   \n",
      "1  BLAZE DE BURY, Marie Pauline Rose - Baroness               NaN   \n",
      "2  BLAZE DE BURY, Marie Pauline Rose - Baroness               NaN   \n",
      "3                   Appleyard, Ernest Silvanus.               NaN   \n",
      "4                           BROOME, John Henry.               NaN   \n",
      "\n",
      "   Corporate Contributors Former owner  Engraver Issuance type  \\\n",
      "0                     NaN          NaN       NaN   monographic   \n",
      "1                     NaN          NaN       NaN   monographic   \n",
      "2                     NaN          NaN       NaN   monographic   \n",
      "3                     NaN          NaN       NaN   monographic   \n",
      "4                     NaN          NaN       NaN   monographic   \n",
      "\n",
      "                                          Flickr URL  \\\n",
      "0  http://www.flickr.com/photos/britishlibrary/ta...   \n",
      "1  http://www.flickr.com/photos/britishlibrary/ta...   \n",
      "2  http://www.flickr.com/photos/britishlibrary/ta...   \n",
      "3  http://www.flickr.com/photos/britishlibrary/ta...   \n",
      "4  http://www.flickr.com/photos/britishlibrary/ta...   \n",
      "\n",
      "                            Shelfmarks  \n",
      "0    British Library HMNTS 12641.b.30.  \n",
      "1    British Library HMNTS 12626.cc.2.  \n",
      "2    British Library HMNTS 12625.dd.1.  \n",
      "3  British Library HMNTS 10369.bbb.15.  \n",
      "4     British Library HMNTS 9007.d.28.  \n",
      "\n",
      "DataFrame shape: (8287, 6)\n",
      "\n",
      "Column names: ['Place of Publication', 'Date of Publication', 'Publisher', 'Title', 'Author', 'Flickr URL']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"BL-Flickr-Images-Book.csv.csv\")\n",
    "print(df.head())\n",
    "columns_to_drop = ['Edition Statement','Corporate Author', 'Corporate Contributors', 'Former owner', \n",
    "                   'Engraver', 'Contributors', 'Issuance type', 'Shelfmarks']\n",
    "df = df.drop(columns_to_drop, axis=1, inplace=False)\n",
    "\n",
    "# Set 'Identifier' as index\n",
    "df = df.set_index('Identifier')\n",
    "print(\"\\nDataFrame shape:\", df.shape)\n",
    "print(\"\\nColumn names:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c35c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXPLORING DATE OF PUBLICATION\n",
      "================================================================================\n",
      "\n",
      "Total records: 8287\n",
      "Non-null dates: 8106\n",
      "Null dates: 181\n",
      "\n",
      "Sample Date of Publication values:\n",
      "Date of Publication\n",
      "1897    157\n",
      "1896    150\n",
      "1893    130\n",
      "1892    127\n",
      "1898    125\n",
      "1895    124\n",
      "1899    120\n",
      "1891    119\n",
      "1894    118\n",
      "1890    115\n",
      "1889    113\n",
      "1876    113\n",
      "1888    105\n",
      "1880    103\n",
      "1887     99\n",
      "1884     96\n",
      "1886     93\n",
      "1878     93\n",
      "1869     92\n",
      "1881     91\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "EXPLORING PLACE OF PUBLICATION\n",
      "================================================================================\n",
      "Non-null places: 8287\n",
      "Null places: 0\n",
      "\n",
      "Sample Place of Publication values:\n",
      "Place of Publication\n",
      "London            3868\n",
      "Paris              479\n",
      "Edinburgh          208\n",
      "New York           177\n",
      "Leipzig            119\n",
      "Philadelphia        89\n",
      "Berlin              70\n",
      "Boston [Mass.]      52\n",
      "Dublin              48\n",
      "Glasgow             45\n",
      "Oxford              44\n",
      "Boston              41\n",
      "Wien                38\n",
      "Madrid              33\n",
      "Stockholm           33\n",
      "Bruxelles           28\n",
      "Cambridge           26\n",
      "Amsterdam           25\n",
      "Stuttgart           24\n",
      "Firenze             24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore Date of Publication and Place of Publication columns\n",
    "print(\"=\"*80)\n",
    "print(\"EXPLORING DATE OF PUBLICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal records: {len(df)}\")\n",
    "print(f\"Non-null dates: {df['Date of Publication'].notna().sum()}\")\n",
    "print(f\"Null dates: {df['Date of Publication'].isna().sum()}\")\n",
    "\n",
    "print(\"\\nSample Date of Publication values:\")\n",
    "print(df['Date of Publication'].value_counts().head(20))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPLORING PLACE OF PUBLICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Non-null places: {df['Place of Publication'].notna().sum()}\")\n",
    "print(f\"Null places: {df['Place of Publication'].isna().sum()}\")\n",
    "\n",
    "print(\"\\nSample Place of Publication values:\")\n",
    "print(df['Place of Publication'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac043604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLEANING DATE OF PUBLICATION\n",
      "================================================================================\n",
      "\n",
      "Successfully cleaned 8104 date records\n",
      "\n",
      "Cleaned Date of Publication (Year only):\n",
      "count    8104.000000\n",
      "mean     1857.813425\n",
      "std        41.551554\n",
      "min      1510.000000\n",
      "25%      1844.000000\n",
      "50%      1868.000000\n",
      "75%      1887.000000\n",
      "max      1915.000000\n",
      "Name: Date of Publication (cleaned), dtype: float64\n",
      "\n",
      "Year range: 1510.0 - 1915.0\n",
      "\n",
      "Before/After Examples:\n",
      "               Original  Cleaned\n",
      "Identifier                      \n",
      "206         1879 [1878]   1879.0\n",
      "216                1868   1868.0\n",
      "218                1869   1869.0\n",
      "472                1851   1851.0\n",
      "480                1857   1857.0\n",
      "481                1875   1875.0\n",
      "519                1872   1872.0\n",
      "874                1676   1676.0\n",
      "1143               1679   1679.0\n",
      "1280               1802   1802.0\n"
     ]
    }
   ],
   "source": [
    "# CLEANING AND STANDARDIZING DATE OF PUBLICATION\n",
    "print(\"=\"*80)\n",
    "print(\"CLEANING DATE OF PUBLICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def clean_date_of_publication(date_str):\n",
    "    \"\"\"\n",
    "    Extract the primary publication year from date strings.\n",
    "    Handles formats like:\n",
    "    - '1879' -> 1879\n",
    "    - '1879 [1878]' -> 1879 (first year)\n",
    "    - '[1879]' -> 1879\n",
    "    - '1879?' -> 1879\n",
    "    - NaN -> NaN\n",
    "    \"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    \n",
    "    date_str = str(date_str).strip()\n",
    "    \n",
    "    # Extract first 4-digit year found\n",
    "    import re\n",
    "    match = re.search(r'\\d{4}', date_str)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Apply cleaning\n",
    "df['Date of Publication (cleaned)'] = df['Date of Publication'].apply(clean_date_of_publication)\n",
    "\n",
    "print(f\"\\nSuccessfully cleaned {df['Date of Publication (cleaned)'].notna().sum()} date records\")\n",
    "print(f\"\\nCleaned Date of Publication (Year only):\")\n",
    "print(df['Date of Publication (cleaned)'].describe())\n",
    "print(f\"\\nYear range: {df['Date of Publication (cleaned)'].min()} - {df['Date of Publication (cleaned)'].max()}\")\n",
    "\n",
    "# Show before/after samples\n",
    "print(\"\\nBefore/After Examples:\")\n",
    "sample_indices = df[df['Date of Publication'].notna()].index[:10]\n",
    "comparison = pd.DataFrame({\n",
    "    'Original': df.loc[sample_indices, 'Date of Publication'],\n",
    "    'Cleaned': df.loc[sample_indices, 'Date of Publication (cleaned)']\n",
    "})\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54768f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLEANING PLACE OF PUBLICATION\n",
      "================================================================================\n",
      "\n",
      "Successfully cleaned 8287 place records\n",
      "\n",
      "Cleaned Place of Publication - Top 20:\n",
      "Place of Publication (cleaned)\n",
      "London          3923\n",
      "Paris            481\n",
      "Edinburgh        211\n",
      "New York         179\n",
      "Leipzig          119\n",
      "Boston            99\n",
      "Philadelphia      90\n",
      "Berlin            70\n",
      "Dublin            48\n",
      "Glasgow           45\n",
      "Oxford            44\n",
      "Vienna            39\n",
      "Madrid            34\n",
      "Cambridge         33\n",
      "Stockholm         33\n",
      "Brussels          29\n",
      "Florence          26\n",
      "Amsterdam         25\n",
      "Chicago           24\n",
      "Stuttgart         24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Before/After Examples (Places with Changes):\n",
      "✓ 'London; Virtue & Yorston' -> 'London'\n",
      "✓ 'Boston [Mass.]' -> 'Boston'\n",
      "✓ 'Wien' -> 'Vienna'\n",
      "✓ 'Paris' -> 'Paris'\n",
      "✓ 'Bruxelles' -> 'Brussels'\n",
      "\n",
      "Total unique cleaned places: 1361\n"
     ]
    }
   ],
   "source": [
    "# CLEANING AND STANDARDIZING PLACE OF PUBLICATION\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLEANING PLACE OF PUBLICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define mapping for city name standardization (non-English names and variants)\n",
    "place_mapping = {\n",
    "    'Wien': 'Vienna',\n",
    "    'Bruxelles': 'Brussels',\n",
    "    'Firenze': 'Florence',\n",
    "    'Milano': 'Milan',\n",
    "    'Napoli': 'Naples',\n",
    "    'Torino': 'Turin',\n",
    "    'Roma': 'Rome',\n",
    "    'Venezia': 'Venice',\n",
    "    'Gent': 'Ghent',\n",
    "    'Den Haag': 'The Hague',\n",
    "    'Köln': 'Cologne',\n",
    "    'München': 'Munich',\n",
    "    'Zürich': 'Zurich',\n",
    "    'København': 'Copenhagen',\n",
    "    'Lund': 'Lund',\n",
    "    'Basel': 'Basel',\n",
    "    'Bern': 'Bern',\n",
    "    'Freiburg': 'Freiburg',\n",
    "}\n",
    "\n",
    "def clean_place_of_publication(place_str):\n",
    "    \"\"\"\n",
    "    Standardize place of publication:\n",
    "    1. Handle semicolon-separated multiple locations (take first)\n",
    "    2. Remove state/province codes like [Mass.], [N.Y.]\n",
    "    3. Standardize non-English city names\n",
    "    4. Strip whitespace\n",
    "    \"\"\"\n",
    "    if pd.isna(place_str):\n",
    "        return None\n",
    "    \n",
    "    place_str = str(place_str).strip()\n",
    "    \n",
    "    # Split by semicolon and take first location\n",
    "    if ';' in place_str:\n",
    "        place_str = place_str.split(';')[0].strip()\n",
    "    \n",
    "    # Remove state/province codes in brackets\n",
    "    import re\n",
    "    place_str = re.sub(r'\\s*\\[.*?\\]\\s*', '', place_str).strip()\n",
    "    \n",
    "    # Apply standardization mapping\n",
    "    for non_english, english in place_mapping.items():\n",
    "        if place_str == non_english:\n",
    "            place_str = english\n",
    "    \n",
    "    return place_str if place_str else None\n",
    "\n",
    "# Apply cleaning\n",
    "df['Place of Publication (cleaned)'] = df['Place of Publication'].apply(clean_place_of_publication)\n",
    "\n",
    "print(f\"\\nSuccessfully cleaned {df['Place of Publication (cleaned)'].notna().sum()} place records\")\n",
    "\n",
    "print(\"\\nCleaned Place of Publication - Top 20:\")\n",
    "print(df['Place of Publication (cleaned)'].value_counts().head(20))\n",
    "\n",
    "# Show before/after for places with multiple values or state codes\n",
    "print(\"\\nBefore/After Examples (Places with Changes):\")\n",
    "sample_data = [\n",
    "    ('London; Virtue & Yorston', 'London'),\n",
    "    ('Boston [Mass.]', 'Boston'),\n",
    "    ('Wien', 'Vienna'),\n",
    "    ('Paris', 'Paris'),\n",
    "    ('Bruxelles', 'Brussels'),\n",
    "]\n",
    "\n",
    "for original, expected in sample_data:\n",
    "    actual = clean_place_of_publication(original)\n",
    "    status = \"✓\" if actual == expected else \"✗\"\n",
    "    print(f\"{status} '{original}' -> '{actual}'\")\n",
    "\n",
    "print(f\"\\nTotal unique cleaned places: {df['Place of Publication (cleaned)'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3d69e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA CLEANING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "               Column  Original Non-null  Cleaned Non-null Data Quality  Unique Values\n",
      " Date of Publication               8106              8104        97.8%            255\n",
      "Place of Publication               8287              8287       100.0%           1361\n",
      "\n",
      "================================================================================\n",
      "CLEANED DATA SAMPLES\n",
      "================================================================================\n",
      "\n",
      "                            Place of Publication       Place of Publication (cleaned) Date of Publication  Date of Publication (cleaned)\n",
      "Identifier                                                                                                                             \n",
      "206                                      London                               London         1879 [1878]                         1879.0\n",
      "216                    London; Virtue & Yorston                               London                1868                         1868.0\n",
      "218                                      London                               London                1869                         1869.0\n",
      "472                                      London                               London                1851                         1851.0\n",
      "480                                      London                               London                1857                         1857.0\n",
      "481                                      London                               London                1875                         1875.0\n",
      "519                                      London                               London                1872                         1872.0\n",
      "667         pp. 40. G. Bryan & Co: Oxford, 1898  pp. 40. G. Bryan & Co: Oxford, 1898                 NaN                            NaN\n",
      "874                                     London]                              London]                1676                         1676.0\n",
      "1143                                     London                               London                1679                         1679.0\n",
      "1280                                   Coventry                             Coventry                1802                         1802.0\n",
      "1808                                Christiania                          Christiania                1859                         1859.0\n",
      "1905                                    Firenze                             Florence                1888                         1888.0\n",
      "1929                                  Amsterdam                            Amsterdam         1839, 38-54                         1839.0\n",
      "2836                                     Savona                               Savona                1897                         1897.0\n",
      "\n",
      "================================================================================\n",
      "TEMPORAL DISTRIBUTION (Cleaned Years)\n",
      "================================================================================\n",
      "\n",
      "Decade Distribution:\n",
      "Decade\n",
      "1510       1\n",
      "1540       1\n",
      "1570       1\n",
      "1590       1\n",
      "1600       4\n",
      "1620       2\n",
      "1630      13\n",
      "1640       9\n",
      "1650       9\n",
      "1660      15\n",
      "1670      25\n",
      "1680      17\n",
      "1690      31\n",
      "1700      14\n",
      "1710      14\n",
      "1720      13\n",
      "1730      34\n",
      "1740      22\n",
      "1750      31\n",
      "1760      41\n",
      "1770      70\n",
      "1780      70\n",
      "1790      84\n",
      "1800     247\n",
      "1810     328\n",
      "1820     385\n",
      "1830     356\n",
      "1840     547\n",
      "1850     818\n",
      "1860     951\n",
      "1870    1044\n",
      "1880    1250\n",
      "1890    1653\n",
      "1900       1\n",
      "1910       2\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "================================================================================\n",
      "GEOGRAPHIC DISTRIBUTION (Cleaned Places)\n",
      "================================================================================\n",
      "\n",
      "Top 15 Publishing Cities:\n",
      "Place of Publication (cleaned)\n",
      "London          3923\n",
      "Paris            481\n",
      "Edinburgh        211\n",
      "New York         179\n",
      "Leipzig          119\n",
      "Boston            99\n",
      "Philadelphia      90\n",
      "Berlin            70\n",
      "Dublin            48\n",
      "Glasgow           45\n",
      "Oxford            44\n",
      "Vienna            39\n",
      "Madrid            34\n",
      "Cambridge         33\n",
      "Stockholm         33\n"
     ]
    }
   ],
   "source": [
    "# SUMMARY AND DATA QUALITY REPORT\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = {\n",
    "    'Column': ['Date of Publication', 'Place of Publication'],\n",
    "    'Original Non-null': [\n",
    "        df['Date of Publication'].notna().sum(),\n",
    "        df['Place of Publication'].notna().sum()\n",
    "    ],\n",
    "    'Cleaned Non-null': [\n",
    "        df['Date of Publication (cleaned)'].notna().sum(),\n",
    "        df['Place of Publication (cleaned)'].notna().sum()\n",
    "    ],\n",
    "    'Data Quality': [\n",
    "        f\"{(df['Date of Publication (cleaned)'].notna().sum() / len(df) * 100):.1f}%\",\n",
    "        f\"{(df['Place of Publication (cleaned)'].notna().sum() / len(df) * 100):.1f}%\"\n",
    "    ],\n",
    "    'Unique Values': [\n",
    "        df['Date of Publication (cleaned)'].nunique(),\n",
    "        df['Place of Publication (cleaned)'].nunique()\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\", summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLEANED DATA SAMPLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display sample records with both original and cleaned columns\n",
    "sample_records = df[['Place of Publication', 'Place of Publication (cleaned)', \n",
    "                     'Date of Publication', 'Date of Publication (cleaned)']].head(15)\n",
    "print(\"\\n\", sample_records.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEMPORAL DISTRIBUTION (Cleaned Years)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nDecade Distribution:\")\n",
    "df['Decade'] = (df['Date of Publication (cleaned)'] // 10 * 10).astype('Int64')\n",
    "decade_dist = df['Decade'].value_counts().sort_index()\n",
    "print(decade_dist)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GEOGRAPHIC DISTRIBUTION (Cleaned Places)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTop 15 Publishing Cities:\")\n",
    "print(df['Place of Publication (cleaned)'].value_counts().head(15).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
